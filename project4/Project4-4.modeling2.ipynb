{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project4-4.modeling2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMDsTiOiWTjtOnCwcoxnRzw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Si167JIAQ7NR","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"error","timestamp":1620265947214,"user_tz":-540,"elapsed":912,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"ee8a41dd-414f-479a-99c3-59f8e02fbb1c"},"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import random\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import os\n","import mxnet as mx\n","import multiprocessing as mp\n","import gluonnlp as nlp\n","\n","from mxnet import gluon, nd, init\n","from mxnet.gluon import nn, rnn\n","from mxnet import autograd, gluon, nd\n","from d2l import try_gpu\n","import pandas as pd\n","\n","# iUse sklearn's metric function to evaluate the results of the experiment\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","main_seed = 21\n","\n","np.random.seed(main_seed)\n","random.seed(main_seed)\n","tf.random.set_seed(main_seed)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-12e991e01adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgluonnlp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mxnet'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"deOzJCMFRNu1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620265772729,"user_tz":-540,"elapsed":39446,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"424140d2-ee00-4364-c3b7-4a912085692c"},"source":["drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O6Nj2kDBREPe","executionInfo":{"status":"ok","timestamp":1620265776527,"user_tz":-540,"elapsed":927,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}}},"source":["base_path = '/content/drive/MyDrive/project4/IMDB'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTKeFARGRJPM","executionInfo":{"status":"ok","timestamp":1620265777800,"user_tz":-540,"elapsed":607,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}}},"source":["import pickle\n","import gzip\n","\n","def load_data(file_name):\n","  global base_path\n","  with gzip.open(os.path.join(base_path, file_name), 'rb') as f:\n","    return pickle.load(f)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxIBcRodRT3a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620265852595,"user_tz":-540,"elapsed":74073,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"5a1b65d4-4dcd-4502-f90c-af7e0efc585f"},"source":["# 파일 \n","print('X_train...')\n","X_train = load_data('X_train_word.pickle')\n","print('X_val...')\n","X_val = load_data('X_val_word.pickle')\n","print('X_test...')\n","X_test = load_data('X_test_word.pickle')\n","\n","print('y_train...')\n","y_train = load_data('y_train.pickle')\n","print('y_val...')\n","y_val = load_data('y_val.pickle')\n","print('y_test...')\n","y_test = load_data('y_test.pickle')\n","\n","print('embeddings...')\n","embeddings = load_data('embeddings.pickle')\n","\n","print('max_seq_len...')\n","max_seq_len = load_data('max_len.pickle')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["X_train...\n","X_val...\n","X_test...\n","y_train...\n","y_val...\n","y_test...\n","embeddings...\n","max_seq_len...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZW8VE05YRsgN"},"source":["#### 기준모델"]},{"cell_type":"code","metadata":{"id":"lIDQX8FkR7TZ","executionInfo":{"status":"ok","timestamp":1620265880917,"user_tz":-540,"elapsed":2322,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}}},"source":["import keras\n","import keras.backend as K\n","from keras.layers import Input, Embedding, LSTM, Lambda, concatenate, Dropout, Flatten, Dense, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, BatchNormalization, MaxPooling1D\n","from keras.models import Model\n","from keras import initializers\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","np.random.seed(main_seed)\n","tf.random.set_seed(main_seed)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlDzNtOXRgci","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620265883211,"user_tz":-540,"elapsed":1493,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"4094c4b1-200f-4c4e-b1ab-a9464b3f5e34"},"source":["from scipy import stats\n","\n","# 최빈 클래스 확인\n","mode_class = stats.mode(y_train)\n","print(mode_class)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["ModeResult(mode=array([False]), count=array([171327]))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_M3knBNXRu-q","executionInfo":{"status":"ok","timestamp":1620265886344,"user_tz":-540,"elapsed":2275,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"75a17c40-998f-4252-aec1-3e421007d62a"},"source":["y_pred = [mode_class[0]] * len(y_val)\n","print('val accuracy:', accuracy_score(y_val, y_pred))\n","print('val f1_score:', f1_score(y_val, y_pred))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["val accuracy: 0.7735757050361661\n","val f1_score: 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"SD_QFy1BX1jd","executionInfo":{"status":"error","timestamp":1620265894654,"user_tz":-540,"elapsed":1586,"user":{"displayName":"Gi Lim Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjvHTgFFGa68Cgi1S9MZqZKI4NKCMedr422sK7Q=s64","userId":"02073828752830425243"}},"outputId":"35fc78c4-2fcf-4d55-d3aa-b2160619b063"},"source":["# custom attention layer\n","# in this class, we want to implement the operation:\n","# softmax(W_2 * tanh(W_1 * H))\n","# where H is the word embedding of the whole sentence, of shape (num_of_word, embed_size)\n","class SelfAttention(nn.HybridBlock):\n","    def __init__(self, att_unit, att_hops, **kwargs):\n","        super(SelfAttention, self).__init__(**kwargs)\n","        with self.name_scope():\n","            # this layer is tanh(w_1 * H), the att_unit corresponds to d_a in the essay\n","            self.ut_dense = nn.Dense(att_unit, activation='tanh', flatten=False)\n","            # this layer implements the multiple hops\n","            self.et_dense = nn.Dense(att_hops, activation=None, flatten=False)\n","\n","    def hybrid_forward(self, F, x): # F is the backend which implements the tensor operation\n","        # x shape: [batch_size, seq_len, embedding_width]\n","        # ut shape: [batch_size, seq_len, att_unit]\n","        ut = self.ut_dense(x) # batch_size * seq_len [* embed_size * embed_size *] att_unit\n","        # et shape: [batch_size, seq_len, att_hops]\n","        et = self.et_dense(ut)# batch_size * seq_len [* att_unit * att_unit *] att_hops\n","\n","        # att shape: [batch_size,  att_hops, seq_len]\n","        # softmax is performed along the seq_len dimension\n","        att = F.softmax(F.transpose(et, axes=(0, 2, 1)), axis=-1)\n","        # output shape [batch_size, att_hops, embedding_width]\n","        output = F.batch_dot(att, x)\n","        # output is the weighted matrix representation of the matrix\n","        # att is the weighted vector we use as attention\n","        return output, att\n","    \n","# d_a = 20, hops = 5\n","print(SelfAttention(20, 5))"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4c1ab7e205d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# softmax(W_2 * tanh(W_1 * H))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# where H is the word embedding of the whole sentence, of shape (num_of_word, embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHybridBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_hops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSelfAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"]}]},{"cell_type":"code","metadata":{"id":"1i9TLk-iX3x7"},"source":[""],"execution_count":null,"outputs":[]}]}
